{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4+v7TRhSP4EevvuIGqqBa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliAbdallah21/LangGraph-QA-Workflow/blob/main/LangGraph_QA_Workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YpvL9ZAkltF",
        "outputId": "d7336f34-ae02-4991-f280-a06d3f4c6a07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# @title Installations\n",
        "%pip install -q langgraph langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Imports\n",
        "from langgraph.graph import StateGraph\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "SjtpygYJknJV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title API Disclaimer\n",
        "api_key =userdata.get('OPENAI_API_KEY')\n",
        "llm = ChatOpenAI(model = 'gpt-3.5-turbo', openai_api_key = api_key)"
      ],
      "metadata": {
        "id": "g6yV56RxkqM8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Building a QA Workflow Specific to the Guided Project**\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/BgP-ruk_KS5H8D7iISsJ6A/Screenshot%202024-12-20%20at%204-20-07%E2%80%AFPM.png\" alt=\"Screenshot\" width=\"150\">\n",
        "</div>\n",
        "\n",
        "\n",
        "Now, we are designing a **Question-Answering (QA) workflow** specifically tailored for a guided project. This workflow leverages LangGraph to create modular, state-driven transitions and ensures that questions related to the guided project are prioritized and handled effectively.\n",
        "\n",
        "The workflow evaluates whether a user’s query is relevant to the guided project (for example, what is this guided project about? or what is LangGraph?). For relevant questions, it uses predefined context to generate an informed response. If the query is unrelated to the guided project, the workflow explicitly communicates that there isn’t enough context to provide an answer, ensuring clarity and transparency in interactions.\n",
        "\n",
        "---\n",
        "\n",
        "### **Workflow Description**\n",
        "\n",
        "1. **Input Validation Node**  \n",
        "   - **Purpose**: Ensures the user has entered a valid question.  \n",
        "   - **Flow**: If the input is valid, it proceeds to evaluate the query’s relevance; otherwise, it terminates with an error message.\n",
        "\n",
        "2. **Context Provider Node**  \n",
        "   - **Purpose**: Checks whether the question is specific to the guided project.  \n",
        "     - For relevant questions, it provides predefined project-specific context.  \n",
        "     - For unrelated questions, it sets the context to `null`.  \n",
        "   - **Flow**: Always transitions to the question-answering step, whether or not context is available.\n",
        "\n",
        "3. **LLM Question-Answering Node**  \n",
        "   - **Purpose**: Uses the context (if available) to answer the question.  \n",
        "     - If context is provided, it generates a detailed response.  \n",
        "     - If context is `null`, it responds with: *\"I don't have enough context to answer your question. Please ask about the guided project.\"*\n"
      ],
      "metadata": {
        "id": "9wzs-ypNlPMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Auth State class\n",
        "from typing import TypedDict, Optional\n",
        "\n",
        "class QAState(TypedDict):\n",
        "    question: Optional[str]\n",
        "    context: Optional[str]\n",
        "    answer: Optional[str]"
      ],
      "metadata": {
        "id": "Nr69eqJjkq2B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_state_example = QAState(\n",
        "    question= \"what is the purpose of this guided project?\",\n",
        "    context= \"This project focuses on building a chatbot using Python.\",\n",
        "    answer = None\n",
        ")"
      ],
      "metadata": {
        "id": "VWp9oVaZlRNt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in qa_state_example.items():\n",
        "    print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2naF7pFmD5g",
        "outputId": "b1ff344e-c977-4165-aab1-8151d263ae47"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: what is the purpose of this guided project?\n",
            "context: This project focuses on building a chatbot using Python.\n",
            "answer: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Defining the Input Validation Node**\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/QNWh9LRDo4A3uF5cz4bXcQ/Screenshot%202024-12-20%20at%204-20-07%E2%80%AFPM-mh.png\" alt=\"Screenshot\" width=\"150\">\n",
        "</div>\n",
        "\n",
        "\n",
        "In this node, we validate the user's input (the question). The node checks whether the question is provided and if it's not empty. If the question is empty, it returns an error message indicating that the question cannot be empty. If the question is valid, it proceeds to the next node.\n"
      ],
      "metadata": {
        "id": "608gzAqhmKQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def input_validation_node(state):\n",
        "    # Extract the question from the state, and strip any leading or trailing spaces\n",
        "    question = state.get(\"question\", \"\").strip()\n",
        "\n",
        "    # If the question is empty, return an error message indicating invalid input\n",
        "    if not question:\n",
        "        return {\"valid\": False, \"error\": \"Question cannot be empty.\"}\n",
        "\n",
        "    # If the question is valid, return valid status\n",
        "    return {\"valid\": True}"
      ],
      "metadata": {
        "id": "tmL-J7l3mLaM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_validation_node(qa_state_example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCRbvwY0mVEE",
        "outputId": "fe5e4683-64af-4773-f096-02b8b047207f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'valid': True}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Defining the Context Provider**\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/htDP3RKH9b6X1NHSKME-YQ/Screenshot%202024-12-20%20at%204-20-07%E2%80%AFPM-mh%20-1-.png\" alt=\"Screenshot\" width=\"150\">\n",
        "</div>\n",
        "\n",
        "\n",
        "This node checks if the question is related to the guided project. If it mentions \"LangGraph\" or \"guided project,\" it provides the relevant context. Otherwise, it sets the context to `None':\n"
      ],
      "metadata": {
        "id": "0nmrbWi6mZ-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def context_provider_node(state):\n",
        "    question = state.get(\"question\", \"\").lower()\n",
        "    # Check if the question is related to the guided project\n",
        "    if \"langgraph\" in question or \"guided project\" in question:\n",
        "        context = (\n",
        "            \"This guided project is about using LangGraph, a Python library to design state-based workflows. \"\n",
        "            \"LangGraph simplifies building complex applications by connecting modular nodes with conditional edges.\"\n",
        "        )\n",
        "        return {\"context\": context}\n",
        "    # If unrelated, set context to null\n",
        "    return {\"context\": None}"
      ],
      "metadata": {
        "id": "6-nYJT8nmXEE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Integrating LLM for QA Workflow**  \n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Djs-AScfvwE8fnKButiPXg/Screenshot%202024-12-20%20at%204-20-07%E2%80%AFPM-mh%20-2-.png\" alt=\"Screenshot\" width=\"150\">\n",
        "</div>\n",
        "\n",
        "\n",
        "In this step, we are building a node that utilizes an LLM (Large Language Model) to answer user questions based on the provided context. If the question is unrelated to the guided project, the node handles this gracefully by returning a predefined response. This approach uses OpenAI's gpt 3.5 turbo model through LangChain's `OpenAI` interface.\n"
      ],
      "metadata": {
        "id": "iJXDJl0W6FQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_qa_node(state):\n",
        "    # Extract the question and context from the state\n",
        "    question = state.get(\"question\", \"\")\n",
        "    context = state.get(\"context\", None)\n",
        "\n",
        "    # Check for missing context and return a fallback response\n",
        "    if not context:\n",
        "        return {\"answer\": \"I don't have enough context to answer your question.\"}\n",
        "\n",
        "    # Construct the prompt dynamically\n",
        "    prompt = f\"Context: {context}\\nQuestion: {question}\\nAnswer the question based on the provided context.\"\n",
        "\n",
        "    # Use LangChain's ChatOpenAI to get the response\n",
        "    try:\n",
        "        response = llm.invoke(prompt)\n",
        "        return {\"answer\": response.content.strip()}\n",
        "    except Exception as e:\n",
        "        return {\"answer\": f\"An error occurred: {str(e)}\"}"
      ],
      "metadata": {
        "id": "gSlFgqGd57-t"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_workflow = StateGraph(QAState)"
      ],
      "metadata": {
        "id": "BpwefP407uDo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_workflow.add_node(\"InputNode\", input_validation_node)\n",
        "qa_workflow.add_node(\"ContextNode\", context_provider_node)\n",
        "qa_workflow.add_node(\"QANode\", llm_qa_node)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9RfY8uH79qh",
        "outputId": "d8fbd8d3-454e-429a-9e63-d0fa00a64835"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7ca8367ee2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/0K3mU7FSZFw0tnAXiN22ag/Screenshot%202024-12-20%20at%204-20-07%E2%80%AFPM-mh%20-3-.png\" alt=\"Screenshot\" width=\"150\">\n",
        "</div>\n",
        "\n",
        "\n",
        "Now, we set the **entry point** for our QA workflow to the **`InputNode`**. This is the first node that will be executed when the workflow starts, ensuring that the user's input is validated before any other operations occur.\n"
      ],
      "metadata": {
        "id": "caDvikpQ8Gy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_workflow.set_entry_point(\"InputNode\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoFbBsfI8H8s",
        "outputId": "143eb389-1561-4f07-cdee-7ab8103fc6f2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7ca8367ee2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END\n",
        "\n",
        "qa_workflow.add_edge(\"InputNode\", \"ContextNode\")\n",
        "qa_workflow.add_edge(\"ContextNode\", \"QANode\")\n",
        "qa_workflow.add_edge(\"QANode\", END)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLApEqIl8QPu",
        "outputId": "2e880c1b-675c-4334-e444-302c3e62578e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7ca8367ee2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_app = qa_workflow.compile()"
      ],
      "metadata": {
        "id": "afjX0PmE8lId"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_app.invoke({\"question\": \"What is the weather today?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4gmJxEj8lup",
        "outputId": "eeccdc06-3960-4430-d04a-6594e18b7433"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'What is the weather today?',\n",
              " 'context': None,\n",
              " 'answer': \"I don't have enough context to answer your question.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_app.invoke({\"question\": \"What is LangGraph?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWEpdltk8oEw",
        "outputId": "99a76f0c-33e4-4b96-e981-f2c305996fba"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'What is LangGraph?',\n",
              " 'context': 'This guided project is about using LangGraph, a Python library to design state-based workflows. LangGraph simplifies building complex applications by connecting modular nodes with conditional edges.',\n",
              " 'answer': 'LangGraph is a Python library that simplifies building complex applications by connecting modular nodes with conditional edges to design state-based workflows.'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_app.invoke({\"question\": \"What is the best guided project?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_RSYf5F8tob",
        "outputId": "721f9372-cfaa-402b-a7a8-97d851a712e0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'What is the best guided project?',\n",
              " 'context': 'This guided project is about using LangGraph, a Python library to design state-based workflows. LangGraph simplifies building complex applications by connecting modular nodes with conditional edges.',\n",
              " 'answer': 'The best guided project in this context would be one that focuses on creating a robust state-based workflow using LangGraph. This project should involve designing a workflow with multiple modular nodes connected by conditional edges, demonstrating how LangGraph can simplify the process of building complex applications. By working through this guided project, users can gain a deeper understanding of how to effectively utilize LangGraph in their own projects.'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}